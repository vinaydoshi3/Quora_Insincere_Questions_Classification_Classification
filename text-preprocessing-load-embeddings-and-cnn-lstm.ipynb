{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A lot of the preprocessing is based on Dieter's and Theio Vial's work.\n",
    "#https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings\n",
    "#https://www.kaggle.com/theoviel/improve-your-score-with-some-text-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/quora-insincere-questions-classification/train.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/test.csv\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/README.txt\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n",
      "/kaggle/input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "import pyprind \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import operator\n",
    "import string\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (1306122, 3)\n",
      "Test Shape: (375806, 2)\n",
      "Df Shape:(1681928, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/quora-insincere-questions-classification/train.csv', encoding='utf-8')#.drop('target',axis=1)\n",
    "test = pd.read_csv('../input/quora-insincere-questions-classification/test.csv', encoding='utf-8')\n",
    "df = pd.concat([train,test],axis=0)\n",
    "print(f'''Train Shape: {train.shape}\n",
    "Test Shape: {test.shape}\n",
    "Df Shape:{df.shape}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape:(1306122, 3)\n"
     ]
    }
   ],
   "source": [
    "train = train.sample(frac=1)\n",
    "print(f'Train Shape:{train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, verbose=True):\n",
    "    sentences = sentences.apply(lambda x: x.split()).values\n",
    "    vocab={}    \n",
    "    for sentence in pyprind.prog_bar(sentences):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word]+=1\n",
    "            except KeyError:\n",
    "                vocab[word]=1\n",
    "    return vocab          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embed(file):\n",
    "    def get_coefs(word,*arr): \n",
    "        #print(word,arr)\n",
    "        return word, np.asarray(arr, dtype='float16')\n",
    "    \n",
    "    if file == '../input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='utf8') if len(o)>100)\n",
    "    elif file == '../input/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin':\n",
    "        embeddings_index = KeyedVectors.load_word2vec_format(file, binary=True)\n",
    "    elif file == '../input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin') if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index\n",
    "glove = '../input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "paragram =  '../input/quora-insincere-questions-classification/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "#wiki_news = '../input/quora-insincere-questions-classification/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Paragram embedding\n"
     ]
    }
   ],
   "source": [
    "#print(\"Extracting GloVe embedding\")\n",
    "#embed_glove = load_embed(glove)\n",
    "print(\"Extracting Paragram embedding\")\n",
    "embed_paragram = load_embed(paragram)\n",
    "#print(\"Extracting FastText embedding\")\n",
    "#embed_fasttext = load_embed(wiki_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocab,embeddings_index):\n",
    "    known_words={}\n",
    "    unknown_words={}\n",
    "    nb_known_words=0\n",
    "    nb_unknown_words=0\n",
    "    for word in vocab.keys():\n",
    "        if word in embeddings_index.keys():\n",
    "            known_words[word]=embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        elif word.capitalize() in embeddings_index.keys():\n",
    "            known_words[word] = embeddings_index[word.capitalize()]\n",
    "            nb_known_words += vocab[word]\n",
    "        elif word.lower() in embeddings_index.keys():\n",
    "            known_words[word] = embeddings_index[word.lower()]\n",
    "            nb_known_words += vocab[word]\n",
    "        elif word.upper() in embeddings_index.keys():\n",
    "            known_words[word] = embeddings_index[word.upper()]\n",
    "            nb_known_words += vocab[word]\n",
    "        else:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "    print(f'Found embeddings for {round((len(known_words)/len(vocab))*100,5)}% of the vocab\\nFound embeddings for {round((nb_known_words/(nb_known_words+nb_unknown_words))*100,5)}% of all text')\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1),reverse=True)#[::-1]\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = build_vocab(df['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Glove : \")\n",
    "# oov_glove = check_coverage(vocab, embed_glove)\n",
    "# print(\"Paragram : \")\n",
    "# oov_paragram = check_coverage(vocab, embed_paragram)\n",
    "# #print(\"FastText : \")\n",
    "# #oov_fasttext = check_coverage(vocab, embed_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\n",
    "    \"Trump's\" : 'trump is',\"'cause\": 'because','â€™': \"'\",',cause': 'because',';cause': 'because',\"ain't\": 'am not','ain,t': 'am not',\n",
    "    'ain;t': 'am not','ain´t': 'am not','ain’t': 'am not',\"aren't\": 'are not','â€“': '-','â€œ':'\"',\n",
    "    'aren,t': 'are not','aren;t': 'are not','aren´t': 'are not','aren’t': 'are not',\"can't\": 'cannot',\"can't've\": 'cannot have','can,t': 'cannot','can,t,ve': 'cannot have',\n",
    "    'can;t': 'cannot','can;t;ve': 'cannot have',\n",
    "    'can´t': 'cannot','can´t´ve': 'cannot have','can’t': 'cannot','can’t’ve': 'cannot have',\n",
    "    \"could've\": 'could have','could,ve': 'could have','could;ve': 'could have',\"couldn't\": 'could not',\"couldn't've\": 'could not have','couldn,t': 'could not','couldn,t,ve': 'could not have','couldn;t': 'could not',\n",
    "    'couldn;t;ve': 'could not have','couldn´t': 'could not',\n",
    "    'couldn´t´ve': 'could not have','couldn’t': 'could not','couldn’t’ve': 'could not have','could´ve': 'could have',\n",
    "    'could’ve': 'could have',\"didn't\": 'did not','didn,t': 'did not','didn;t': 'did not','didn´t': 'did not',\n",
    "    'didn’t': 'did not',\"doesn't\": 'does not','doesn,t': 'does not','doesn;t': 'does not','doesn´t': 'does not',\n",
    "    'doesn’t': 'does not',\"don't\": 'do not','don,t': 'do not','don;t': 'do not','don´t': 'do not','don’t': 'do not',\n",
    "    \"hadn't\": 'had not',\"hadn't've\": 'had not have','hadn,t': 'had not','hadn,t,ve': 'had not have','hadn;t': 'had not',\n",
    "    'hadn;t;ve': 'had not have','hadn´t': 'had not','hadn´t´ve': 'had not have','hadn’t': 'had not','hadn’t’ve': 'had not have',\"hasn't\": 'has not','hasn,t': 'has not','hasn;t': 'has not','hasn´t': 'has not','hasn’t': 'has not',\n",
    "    \"haven't\": 'have not','haven,t': 'have not','haven;t': 'have not','haven´t': 'have not','haven’t': 'have not',\"he'd\": 'he would',\n",
    "    \"he'd've\": 'he would have',\"he'll\": 'he will',\n",
    "    \"he's\": 'he is','he,d': 'he would','he,d,ve': 'he would have','he,ll': 'he will','he,s': 'he is','he;d': 'he would',\n",
    "    'he;d;ve': 'he would have','he;ll': 'he will','he;s': 'he is','he´d': 'he would','he´d´ve': 'he would have','he´ll': 'he will',\n",
    "    'he´s': 'he is','he’d': 'he would','he’d’ve': 'he would have','he’ll': 'he will','he’s': 'he is',\"how'd\": 'how did',\"how'll\": 'how will',\n",
    "    \"how's\": 'how is','how,d': 'how did','how,ll': 'how will','how,s': 'how is','how;d': 'how did','how;ll': 'how will',\n",
    "    'how;s': 'how is','how´d': 'how did','how´ll': 'how will','how´s': 'how is','how’d': 'how did','how’ll': 'how will',\n",
    "    'how’s': 'how is',\"i'd\": 'i would',\"i'll\": 'i will',\"i'm\": 'i am',\"i've\": 'i have','i,d': 'i would','i,ll': 'i will',\n",
    "    'i,m': 'i am','i,ve': 'i have','i;d': 'i would','i;ll': 'i will','i;m': 'i am','i;ve': 'i have',\"isn't\": 'is not',\n",
    "    'isn,t': 'is not','isn;t': 'is not','isn´t': 'is not','isn’t': 'is not',\"it'd\": 'it would',\"it'll\": 'it will',\"It's\":'it is',\n",
    "    \"it's\": 'it is','it,d': 'it would','it,ll': 'it will','it,s': 'it is','it;d': 'it would','it;ll': 'it will','it;s': 'it is','it´d': 'it would','it´ll': 'it will','it´s': 'it is',\n",
    "    'it’d': 'it would','it’ll': 'it will','it’s': 'it is',\n",
    "    'i´d': 'i would','i´ll': 'i will','i´m': 'i am','i´ve': 'i have','i’d': 'i would','i’ll': 'i will','i’m': 'i am',\n",
    "    'i’ve': 'i have',\"let's\": 'let us','let,s': 'let us','let;s': 'let us','let´s': 'let us',\n",
    "    'let’s': 'let us',\"ma'am\": 'madam','ma,am': 'madam','ma;am': 'madam',\"mayn't\": 'may not','mayn,t': 'may not','mayn;t': 'may not',\n",
    "    'mayn´t': 'may not','mayn’t': 'may not','ma´am': 'madam','ma’am': 'madam',\"might've\": 'might have','might,ve': 'might have','might;ve': 'might have',\"mightn't\": 'might not','mightn,t': 'might not','mightn;t': 'might not','mightn´t': 'might not',\n",
    "    'mightn’t': 'might not','might´ve': 'might have','might’ve': 'might have',\"must've\": 'must have','must,ve': 'must have','must;ve': 'must have',\n",
    "    \"mustn't\": 'must not','mustn,t': 'must not','mustn;t': 'must not','mustn´t': 'must not','mustn’t': 'must not','must´ve': 'must have',\n",
    "    'must’ve': 'must have',\"needn't\": 'need not','needn,t': 'need not','needn;t': 'need not','needn´t': 'need not','needn’t': 'need not',\"oughtn't\": 'ought not','oughtn,t': 'ought not','oughtn;t': 'ought not',\n",
    "    'oughtn´t': 'ought not','oughtn’t': 'ought not',\"sha'n't\": 'shall not','sha,n,t': 'shall not','sha;n;t': 'shall not',\"shan't\": 'shall not',\n",
    "    'shan,t': 'shall not','shan;t': 'shall not','shan´t': 'shall not','shan’t': 'shall not','sha´n´t': 'shall not','sha’n’t': 'shall not',\n",
    "    \"she'd\": 'she would',\"she'll\": 'she will',\"she's\": 'she is','she,d': 'she would','she,ll': 'she will',\n",
    "    'she,s': 'she is','she;d': 'she would','she;ll': 'she will','she;s': 'she is','she´d': 'she would','she´ll': 'she will',\n",
    "    'she´s': 'she is','she’d': 'she would','she’ll': 'she will','she’s': 'she is',\"should've\": 'should have','should,ve': 'should have','should;ve': 'should have',\n",
    "    \"shouldn't\": 'should not','shouldn,t': 'should not','shouldn;t': 'should not','shouldn´t': 'should not','shouldn’t': 'should not','should´ve': 'should have',\n",
    "    'should’ve': 'should have',\"that'd\": 'that would',\"that's\": 'that is','that,d': 'that would','that,s': 'that is','that;d': 'that would',\n",
    "    'that;s': 'that is','that´d': 'that would','that´s': 'that is','that’d': 'that would','that’s': 'that is',\"there'd\": 'there had',\n",
    "    \"there's\": 'there is','there,d': 'there had','there,s': 'there is','there;d': 'there had','there;s': 'there is',\n",
    "    'there´d': 'there had','there´s': 'there is','there’d': 'there had','there’s': 'there is',\n",
    "    \"they'd\": 'they would',\"they'll\": 'they will',\"they're\": 'they are',\"they've\": 'they have',\n",
    "    'they,d': 'they would','they,ll': 'they will','they,re': 'they are','they,ve': 'they have','they;d': 'they would','they;ll': 'they will','they;re': 'they are',\n",
    "    'they;ve': 'they have','they´d': 'they would','they´ll': 'they will','they´re': 'they are','they´ve': 'they have','they’d': 'they would','they’ll': 'they will',\n",
    "    'they’re': 'they are','they’ve': 'they have',\"wasn't\": 'was not','wasn,t': 'was not','wasn;t': 'was not','wasn´t': 'was not',\n",
    "    'wasn’t': 'was not',\"we'd\": 'we would',\"we'll\": 'we will',\"we're\": 'we are',\"we've\": 'we have','we,d': 'we would','we,ll': 'we will',\n",
    "    'we,re': 'we are','we,ve': 'we have','we;d': 'we would','we;ll': 'we will','we;re': 'we are','we;ve': 'we have',\n",
    "    \"weren't\": 'were not','weren,t': 'were not','weren;t': 'were not','weren´t': 'were not','weren’t': 'were not','we´d': 'we would','we´ll': 'we will',\n",
    "    'we´re': 'we are','we´ve': 'we have','we’d': 'we would','we’ll': 'we will','we’re': 'we are','we’ve': 'we have',\"what'll\": 'what will',\"what're\": 'what are',\"what's\": 'what is',\n",
    "    \"what've\": 'what have','what,ll': 'what will','what,re': 'what are','what,s': 'what is','what,ve': 'what have','what;ll': 'what will','what;re': 'what are',\n",
    "    'what;s': 'what is','what;ve': 'what have','what´ll': 'what will',\n",
    "    'what´re': 'what are','what´s': 'what is','what´ve': 'what have','what’ll': 'what will','what’re': 'what are','what’s': 'what is',\n",
    "    'what’ve': 'what have',\"where'd\": 'where did',\"where's\": 'where is','where,d': 'where did','where,s': 'where is','where;d': 'where did',\n",
    "    'where;s': 'where is','where´d': 'where did','where´s': 'where is','where’d': 'where did','where’s': 'where is',\n",
    "    \"who'll\": 'who will',\"who's\": 'who is','who,ll': 'who will','who,s': 'who is','who;ll': 'who will','who;s': 'who is',\n",
    "    'who´ll': 'who will','who´s': 'who is','who’ll': 'who will','who’s': 'who is',\"won't\": 'will not','won,t': 'will not','won;t': 'will not',\n",
    "    'won´t': 'will not','won’t': 'will not',\"wouldn't\": 'would not','wouldn,t': 'would not','wouldn;t': 'would not','wouldn´t': 'would not',\n",
    "    'wouldn’t': 'would not',\"you'd\": 'you would',\"you'll\": 'you will',\"you're\": 'you are','you,d': 'you would','you,ll': 'you will',\n",
    "    'you,re': 'you are','you;d': 'you would','you;ll': 'you will',\n",
    "    'you;re': 'you are','you´d': 'you would','you´ll': 'you will','you´re': 'you are','you’d': 'you would','you’ll': 'you will','you’re': 'you are',\n",
    "    '´cause': 'because','’cause': 'because',\"you've\": \"you have\",\"could'nt\": 'could not',\n",
    "    \"havn't\": 'have not',\"here’s\": \"here is\",'i\"\"m': 'i am',\"i'am\": 'i am',\"i'l\": \"i will\",\"i'v\": 'i have',\"wan't\": 'want',\"was'nt\": \"was not\",\"who'd\": \"who would\",\n",
    "    \"who're\": \"who are\",\"who've\": \"who have\",\"why'd\": \"why would\",\"would've\": \"would have\",\"y'all\": \"you all\",\"y'know\": \"you know\",\"you.i\": \"you i\",\n",
    "    \"your'e\": \"you are\",\"arn't\": \"are not\",\"agains't\": \"against\",\"c'mon\": \"common\",\"doens't\": \"does not\",'don\"\"t': \"do not\",\"dosen't\": \"does not\",\n",
    "    \"dosn't\": \"does not\",\"shoudn't\": \"should not\",\"that'll\": \"that will\",\"there'll\": \"there will\",\"there're\": \"there are\",\n",
    "    \"this'll\": \"this all\",\"u're\": \"you are\", \"ya'll\": \"you all\",\"you'r\": \"you are\",\"you’ve\": \"you have\",\"d'int\": \"did not\",\"did'nt\": \"did not\",\"din't\": \"did not\",\"dont't\": \"do not\",\"gov't\": \"government\",\n",
    "    \"i'ma\": \"i am\",\"is'nt\": \"is not\",\"‘I\":'I','ᴀɴᴅ':'and','ᴛʜᴇ':'the','ʜᴏᴍᴇ':'home','ᴜᴘ':'up','ʙʏ':'by','ᴀᴛ':'at','…and':'and','civilbeat':'civil beat','TrumpCare':'Trump care','Trumpcare':'Trump care', 'OBAMAcare':'Obama care','ᴄʜᴇᴄᴋ':'check','ғᴏʀ':'for','ᴛʜɪs':'this','ᴄᴏᴍᴘᴜᴛᴇʀ':'computer','ᴍᴏɴᴛʜ':'month','ᴡᴏʀᴋɪɴɢ':'working','ᴊᴏʙ':'job','ғʀᴏᴍ':'from','Sᴛᴀʀᴛ':'start','gubmit':'submit','CO₂':'carbon dioxide','ғɪʀsᴛ':'first','ᴇɴᴅ':'end','ᴄᴀɴ':'can','ʜᴀᴠᴇ':'have','ᴛᴏ':'to','ʟɪɴᴋ':'link','ᴏғ':'of','ʜᴏᴜʀʟʏ':'hourly','ᴡᴇᴇᴋ':'week','ᴇɴᴅ':'end','ᴇxᴛʀᴀ':'extra','Gʀᴇᴀᴛ':'great','sᴛᴜᴅᴇɴᴛs':'student','sᴛᴀʏ':'stay','ᴍᴏᴍs':'mother','ᴏʀ':'or','ᴀɴʏᴏɴᴇ':'anyone','ɴᴇᴇᴅɪɴɢ':'needing','ᴀɴ':'an','ɪɴᴄᴏᴍᴇ':'income',\n",
    "    'ʀᴇʟɪᴀʙʟᴇ':'reliable','ғɪʀsᴛ':'first','ʏᴏᴜʀ':'your','sɪɢɴɪɴɢ':'signing','ʙᴏᴛᴛᴏᴍ':'bottom','ғᴏʟʟᴏᴡɪɴɢ':'following','Mᴀᴋᴇ':'make',\n",
    "    'ᴄᴏɴɴᴇᴄᴛɪᴏɴ':'connection','ɪɴᴛᴇʀɴᴇᴛ':'internet','financialpost':'financial post', 'ʜaᴠᴇ':' have ', 'ᴄaɴ':' can ', 'Maᴋᴇ':' make ', 'ʀᴇʟɪaʙʟᴇ':' reliable ', 'ɴᴇᴇᴅ':' need ',\n",
    "    'ᴏɴʟʏ':' only ', 'ᴇxᴛʀa':' extra ', 'aɴ':' an ', 'aɴʏᴏɴᴇ':' anyone ', 'sᴛaʏ':' stay ', 'Sᴛaʀᴛ':' start', 'SHOPO':'shop',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = pyprind.ProgBar(df.shape[0], bar_char='█')\n",
    "def clean_contractions(text, mapping):\n",
    "    #text_val = text.lower()\n",
    "    #map_val = \n",
    "    for word in mapping.keys():\n",
    "        word_val = word.lower()\n",
    "        if word in text:\n",
    "            text = text.replace(word, mapping[word])\n",
    "        elif word_val in text:\n",
    "            text = text.replace(word_val, mapping[word])\n",
    "#         elif word.lower() in text:\n",
    "#             text = text.replace(word, mapping[word])\n",
    "#         elif word.capitalize() in text:\n",
    "#             text = text.replace(word, mapping[word])\n",
    "#         elif word.upper() in text:\n",
    "#             text = text.replace(word, mapping[word])\n",
    "\n",
    "    bar.update()\n",
    "    return text\n",
    "#df['lowered_question'] = df['question_text'].apply(lambda x: x.lower())\n",
    "#df['treated_question'] = df['lowered_question'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "#train['lowered_question'] = train['question_text'].apply(lambda x: x.lower())\n",
    "#test['lowered_question'] = test['question_text'].apply(lambda x: x.lower())\n",
    "#train['treated_question'] = train['lowered_question'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "#test['treated_question'] = test['lowered_question'].apply(lambda x: clean_contractions(x, contraction_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2 = df.copy()\n",
    "#df = df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = build_vocab(df['treated_question'])\n",
    "# print(\"Glove : \")\n",
    "# oov_glove = check_coverage(vocab, embed_glove)\n",
    "# print(\"Paragram : \")\n",
    "# oov_paragram = check_coverage(vocab, embed_paragram)\n",
    "# #print(\"FastText : \")\n",
    "# #oov_fasttext = check_coverage(vocab, embed_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_punct = [\n",
    "#     ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "#     '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    "#     '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
    "#     '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
    "#     '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
    "#     '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
    "#     '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "#     'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "#     '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "#     '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "#punct = list(set(list(punct)+extra_punct+list(string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragram:\n",
      "“ ” ’ ∞ θ ÷ α • à − β ∅ ³ π ‘ ₹ ´ ° £ € × ™ √ ² — – \n"
     ]
    }
   ],
   "source": [
    "def unknown_punct(embed, punct):\n",
    "    unknown_punct=''\n",
    "    for val in punct:\n",
    "        if val not in embed:\n",
    "            unknown_punct += val+' '\n",
    "    return unknown_punct\n",
    "#print(f'Glove:\\n{unknown_punct(embed_glove, punct)}')\n",
    "print(f'Paragram:\\n{unknown_punct(embed_paragram, punct)}')\n",
    "#print(f'FastText:\\n{unknown_punct(embed_fasttext, punct)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = pyprind.ProgBar(df.shape[0], bar_char='█')\n",
    "def clean_puncts(text, mapping, punct):\n",
    "    for p in punct_mapping.keys():\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}\n",
    "    for p in specials.keys():\n",
    "        text = text.replace(p, specials[p])\n",
    "    bar.update()    \n",
    "    return text\n",
    "#df['treated_question'] = df['treated_question'].apply(lambda x: clean_puncts(x, punct_mapping, punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = build_vocab(df['treated_question'])\n",
    "# print(\"Glove : \")\n",
    "# oov_glove = check_coverage(vocab, embed_glove)\n",
    "# print(\"Paragram : \")\n",
    "# oov_paragram = check_coverage(vocab, embed_paragram)\n",
    "# #print(\"FastText : \")\n",
    "# #oov_fasttext = check_coverage(vocab, embed_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oov_paragram[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'lnmiit':'limit', 'quorans': 'users of quora', 'mhcet':'competitive examination', 'swachh':'clean', 'chapterwise':'chapter wise', 'bitconnect':'cryptocurrency', 'bittrex':'cryptocurrency exchange','koinex':'cryptocurrency exchange', 'zebpay':'cryptocurrency exchange', 'binance':'cryptocurrency exchange', 'coinbase':'cryptocurrency exchange', 'brexit':'exit of UK from European Union', 'cryptocurrencies':'multiple cryptocurrency','redmi':'mobile phone', 'oneplus':'mobile phone company', 'pokémon':'anime', 'boruto':'anime', 'bhakts':'loyal followers', 'litecoin':'cryptocurreny','qoura':'quora','altcoin':'cryptocurreny','blockchains':'blockchain', 'airpods':'wireless earphones','zenfone':'mobile phone','altcoins':'multiple cryptocurrency','electroneum':'cryptocurreny','cryptocurreny':'blockchain based currency','iitians':'students','iitian':'student','gdpr':'data protection law'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = pyprind.ProgBar(df.shape[0], bar_char='█')\n",
    "def correct_spell(text, dic):\n",
    "    for word in dic.keys():\n",
    "        text = text.replace(word, dic[word])\n",
    "    bar.update()\n",
    "    return text\n",
    "#df['treated_question'] = df['treated_question'].apply(lambda x: correct_spell(x, mispell_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = build_vocab(df['treated_question'])\n",
    "# print(\"Glove : \")\n",
    "# oov_glove = check_coverage(vocab, embed_glove)\n",
    "# print(\"Paragram : \")\n",
    "# oov_paragram = check_coverage(vocab, embed_paragram)\n",
    "# #print(\"FastText : \")\n",
    "# #oov_fasttext = check_coverage(vocab, embed_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del embed_glove\n",
    "# del oov_glove\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:01\n"
     ]
    }
   ],
   "source": [
    "train['treated_question'] = train['question_text'].apply(lambda x: x.lower())\n",
    "test['treated_question'] = test['question_text'].apply(lambda x: x.lower())\n",
    "train['treated_question'] = train['treated_question'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "test['treated_question'] = test['treated_question'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "train['treated_question'] = train['treated_question'].apply(lambda x: clean_puncts(x, punct_mapping, punct))\n",
    "test['treated_question'] = test['treated_question'].apply(lambda x: clean_puncts(x, punct_mapping, punct))\n",
    "train['treated_question'] = train['treated_question'].apply(lambda x: correct_spell(x, mispell_dict))\n",
    "test['treated_question'] = test['treated_question'].apply(lambda x: correct_spell(x, mispell_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten,Dense, Embedding,  Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Concatenate, Input, Dropout,Bidirectional, CuDNNGRU, GlobalAveragePooling1D, GlobalMaxPooling1D, LeakyReLU, Activation, CuDNNLSTM, SpatialDropout1D\n",
    "#Dense, Embedding, Bidirectional, CuDNNGRU, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, Input, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_to_keep = 100000\n",
    "#train['treated_question'].map(len).mean()\n",
    "max_len = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_data(text):\n",
    "#     t = Tokenizer(num_words=length_to_keep)\n",
    "#     t.fit_on_texts(text)\n",
    "#     text = t.texts_to_sequences(text)\n",
    "#     text = pad_sequences(text, maxlen=max_len)\n",
    "#     return text, t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, word_index = tokenize_data(train['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_treated_data(text, text_test):\n",
    "    t = Tokenizer(num_words=length_to_keep, filters='')\n",
    "    t.fit_on_texts(text)\n",
    "    text = t.texts_to_sequences(text)\n",
    "    text_test = t.texts_to_sequences(text_test)\n",
    "    text = pad_sequences(text, maxlen=max_len)\n",
    "    text_test = pad_sequences(text_test, maxlen=max_len)\n",
    "    return text, t.word_index, text_test\n",
    "X_treated, word_index_treated, X_test_treated = tokenize_treated_data(train['treated_question'], test['treated_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# , _ = tokenize_treated_data(test['treated_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len_treated = len(word_index_treated)+1\n",
    "def embed_matrix(embed_paragram, word_index, length_to_keep):\n",
    "    embeddings = np.stack(embed_paragram.values())\n",
    "    \n",
    "#    embeddings_mean, embeddings_std = embeddings.mean(), embeddings.std(ddof=1)\n",
    "#    print(embeddings_mean)\n",
    "     \n",
    "    embeddings_shape = embeddings.shape[1]\n",
    "    embedding_matrix = np.zeros((length_to_keep, 300))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= length_to_keep:\n",
    "            continue\n",
    "        embeddings_vector = embed_paragram.get(word)\n",
    "        if embeddings_vector is not None:\n",
    "            embedding_matrix[i] = embeddings_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "#embedding = embed_matrix(embed_paragram, word_index, length_to_keep)\n",
    "embedding_treated = embed_matrix(embed_paragram, word_index_treated, length_to_keep)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_treated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del embed_paragram\n",
    "\n",
    "#del embed_fasttext\n",
    "#del word_index\n",
    "del word_index_treated\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {k: embed_glove[k] for k in list(embed_glove)[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_target = pd.read_csv('../input/quora-insincere-questions-classification/train.csv', encoding='utf-8')\n",
    "y = train['target'].values\n",
    "train.drop(columns='target',inplace=True)\n",
    "# del train_target\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1175509 texts\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_chk, y_train, y_chk = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "X_t_train, X_t_chk, y_train_treated, y_chk_treated = train_test_split(X_treated, y, test_size=0.1, random_state=0)\n",
    "print(f'Training on {X_t_train.shape[0]} texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f1(y_true, y_pred):\n",
    "#     precision,recall,fscore,support = precision_recall_fscore_support(y_true,y_pred,average='macro')\n",
    "#     print (f'Precision : {precision}')\n",
    "#     print (f'Recall : {recall}')\n",
    "#     print (f'Fscore : {fscore}')\n",
    "#     print (f'Precision : {precision}')\n",
    "#     return fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_model1(embedding_matrix, embed_size=300, loss='binary_crossentropy'):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(length_to_keep, embed_size, input_length=max_len,weights=[embedding_matrix], trainable=False))\n",
    "#     model.add(Conv1D(filters=2, kernel_size=4, activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(loss=loss, optimizer=Adam(lr=0.1), metrics=['accuracy',f1])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = make_model1(embedding_treated)\n",
    "# model1.summary()\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_model(embedding_matrix, embed_size=300, loss='binary_crossentropy'):\n",
    "#     inp = Input(shape=(max_len,))\n",
    "#     filter_size = [2,3,4,5]\n",
    "#     num_kernels=600\n",
    "#     embed   = Embedding(length_to_keep, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "#     x       = embed\n",
    "#     x1      = Conv1D(kernel_size=filter_size[0], strides=1, filters=num_kernels, padding='valid', activation='relu', use_bias=True)(x)\n",
    "# #    line1   = LeakyReLU()(x1)\n",
    "#     x2      = Conv1D(kernel_size=filter_size[1], strides=1, filters=num_kernels, padding='valid', activation='relu', use_bias=True)(x)\n",
    "# #    line2   = LeakyReLU()(x2)\n",
    "#     x3      = Conv1D(kernel_size=filter_size[2], strides=1, filters=num_kernels, padding='valid', activation='relu', use_bias=True)(x)\n",
    "# #     x4      = Conv1D(kernel_size=filter_size[3], strides=1, filters=num_kernels, padding='valid', activation='relu', use_bias=True)(x)\n",
    "#     x1_max  = MaxPooling1D(pool_size=(2), strides=2, padding='valid')(x1)\n",
    "#     #x1_flat = Flatten()(x1_max)\n",
    "#     x2_max  = MaxPooling1D(pool_size=(2), strides=2, padding='valid')(x2)\n",
    "#     #x2_flat = Flatten()(x2_max)\n",
    "#     x3_max  = MaxPooling1D(pool_size=(2), strides=2, padding='valid')(x3)\n",
    "# #     #x3_flat = Flatten()(x3_max)\n",
    "# #     x4_max  = MaxPooling1D(pool_size=(max_len-filter_size[3]+1), strides=1, padding='valid')(x4)\n",
    "#     concat  = Concatenate(axis=1)([x1_max, x2_max, x3_max])#, x4_max])\n",
    "#     flat    = Flatten()(concat)\n",
    "#     drop    = Dropout(0.3)(flat)\n",
    "#     dense1  = Dense(128, activation=\"relu\")(drop)\n",
    "#     output  = Dense(1, activation=\"sigmoid\")(dense1)\n",
    "#     model   = Model(inputs=inp, outputs=output)\n",
    "#     model.compile(loss=loss, optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "#     return model\n",
    "# #model = make_model(embedding)\n",
    "# #model_treated = make_model(embedding_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_model(embedding_matrix, embed_size=300, loss='binary_crossentropy'):\n",
    "#     inp = Input(shape=(max_len,))\n",
    "#     filter_size = [2,3,4,5]\n",
    "#     num_kernels=64\n",
    "#     embed   = Embedding(length_to_keep, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "#     x       = embed\n",
    "#     x1      = Conv1D(kernel_size=filter_size[0], strides=1, filters=num_kernels, padding='valid', activation='relu', use_bias=True)(x)\n",
    "# #    line1   = LeakyReLU()(x1)\n",
    "#     x2      = Conv1D(kernel_size=filter_size[1], strides=1, filters=num_kernels, padding='valid', activation='relu', use_bias=True)(x)\n",
    "# #    line2   = LeakyReLU()(x2)\n",
    "#     x3      = Conv1D(kernel_size=filter_size[2], strides=1, filters=num_kernels, padding='valid', activation='relu', use_bias=True)(x)\n",
    "# #     x4      = Conv1D(kernel_size=filter_size[3], strides=1, filters=num_kernels, padding='valid', activation='relu', use_bias=True)(x)\n",
    "#     x1_max  = MaxPooling1D(pool_size=(max_len-filter_size[0]+1), strides=1, padding='valid')(x1)\n",
    "#     #x1_flat = Flatten()(x1_max)\n",
    "#     x2_max  = MaxPooling1D(pool_size=(max_len-filter_size[1]+1), strides=1, padding='valid')(x2)\n",
    "#     #x2_flat = Flatten()(x2_max)\n",
    "#     x3_max  = MaxPooling1D(pool_size=(max_len-filter_size[2]+1), strides=1, padding='valid')(x3)\n",
    "# #     #x3_flat = Flatten()(x3_max)\n",
    "# #     x4_max  = MaxPooling1D(pool_size=(max_len-filter_size[3]+1), strides=1, padding='valid')(x4)\n",
    "#     concat  = Concatenate(axis=1)([x1_max, x2_max, x3_max])#, x4_max])\n",
    "#     flat    = Flatten()(concat)\n",
    "#     drop    = Dropout(0.3)(flat)\n",
    "#     dense1  = Dense(64, activation=\"relu\")(drop)\n",
    "#     output  = Dense(1, activation=\"sigmoid\")(dense1)\n",
    "#     model   = Model(inputs=inp, outputs=output)\n",
    "#     model.compile(loss=loss, optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "#     return model\n",
    "# #model = make_model(embedding)\n",
    "# #model_treated = make_model(embedding_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_model(embedding_matrix, embed_size=300, loss='binary_crossentropy'):\n",
    "#     inp    = Input(shape=(max_len,))\n",
    "#     x      = Embedding(length_to_keep, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "#     x      = Bidirectional(CuDNNGRU(128, return_sequences=True))(x)\n",
    "#     x      = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "#     avg_pl = GlobalAveragePooling1D()(x)\n",
    "#     max_pl = GlobalMaxPooling1D()(x)\n",
    "#     concat = concatenate([avg_pl, max_pl])\n",
    "#     dense  = Dense(64, activation=\"relu\")(concat)\n",
    "#     drop   = Dropout(0.1)(concat)\n",
    "#     output = Dense(1, activation=\"sigmoid\")(concat)\n",
    "    \n",
    "#     model  = Model(inputs=inp, outputs=output)\n",
    "#     model.compile(loss=loss, optimizer=Adam(lr=0.0001), metrics=['accuracy', f1])\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(embedding_matrix, embed_size=300, loss='binary_crossentropy'):\n",
    "    inp = Input(shape=(max_len,))\n",
    "    embed= Embedding(length_to_keep, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    spatial_drop = SpatialDropout1D(0.3)(embed)\n",
    "    lstm1=(Bidirectional(CuDNNLSTM(256,return_sequences=True)))(spatial_drop)\n",
    "    lstm2=(Bidirectional(CuDNNGRU(256,return_sequences=True)))(lstm1)\n",
    "    maxpool1 = GlobalMaxPooling1D()(lstm1)\n",
    "    maxpool2 = GlobalMaxPooling1D()(lstm2)\n",
    "    conc = Concatenate(axis=1)([maxpool1,maxpool2])\n",
    "    #flat=Flatten()(lstm2)\n",
    "    #drop2 = Dropout(0.3)(conc)\n",
    "    dense1 = Dense(128,activation='relu')(conc)\n",
    "    output=Dense(1,activation='sigmoid')(dense1)\n",
    "    model  = Model(inputs=inp, outputs=output)\n",
    "    model.compile(loss=loss, optimizer=Adam(lr=0.001), metrics=['accuracy', f1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 75, 300)      30000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 75, 300)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 75, 512)      1142784     spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 75, 512)      1182720     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 512)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 512)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          131200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,456,833\n",
      "Trainable params: 2,456,833\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_treated = make_model(embedding_treated)\n",
    "model_treated.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "#checkpoints = ModelCheckpoint('weights.hdf5', monitor=\"val_f1\", mode=\"max\", verbose=True, save_best_only=True)\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_f1', factor=0.1, patience=2, verbose=1, min_lr=0.000001)\n",
    "# early_stopping = EarlyStopping(patience=2, verbose=1, monitor='val_f1', mode='max')\n",
    "# checkpoints_treated = ModelCheckpoint('treated_weights.hdf5', monitor=\"val_f1\", mode=\"max\", verbose=True, save_best_only=True)\n",
    "# reduce_lr_treated = ReduceLROnPlateau(monitor='val_f1', factor=0.1, patience=2, verbose=1, min_lr=0.1)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, verbose=1, monitor='val_loss', mode='min')\n",
    "checkpoints_treated = ModelCheckpoint('treated_weights.hdf5', monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True)\n",
    "reduce_lr_treated = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, min_lr=0.00001, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1306122 samples, validate on 130613 samples\n",
      "Epoch 1/4\n",
      " - 474s - loss: 0.1134 - accuracy: 0.9554 - f1: 0.5542 - val_loss: 0.0952 - val_accuracy: 0.9622 - val_f1: 0.6586\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09522, saving model to treated_weights.hdf5\n",
      "Epoch 2/4\n",
      " - 470s - loss: 0.0997 - accuracy: 0.9603 - f1: 0.6315 - val_loss: 0.0870 - val_accuracy: 0.9650 - val_f1: 0.6903\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09522 to 0.08698, saving model to treated_weights.hdf5\n",
      "Epoch 3/4\n",
      " - 469s - loss: 0.0938 - accuracy: 0.9624 - f1: 0.6569 - val_loss: 0.0807 - val_accuracy: 0.9676 - val_f1: 0.7040\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08698 to 0.08067, saving model to treated_weights.hdf5\n",
      "Epoch 4/4\n",
      " - 470s - loss: 0.0894 - accuracy: 0.9638 - f1: 0.6739 - val_loss: 0.0764 - val_accuracy: 0.9693 - val_f1: 0.7351\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08067 to 0.07643, saving model to treated_weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# history = model_treated.fit(X_t_train, y_train_treated, batch_size=batch_size,\n",
    "#                             epochs=epochs, \n",
    "#                     validation_data=[X_t_chk, y_chk_treated], \n",
    "#                             verbose=2, callbacks=[checkpoints_treated, reduce_lr_treated, early_stopping])\n",
    "\n",
    "history = model_treated.fit(X_treated, y, batch_size=batch_size,\n",
    "                            epochs=epochs, \n",
    "                    validation_data=[X_t_chk, y_chk_treated], \n",
    "                            verbose=2, callbacks=[checkpoints_treated, reduce_lr_treated, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-90bb48c47686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Test Loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['acc'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 109s 289us/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model_treated.predict(X_test_treated,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 10s 80us/step\n",
      "F1 score at threshold 0.1 is 0.641291617868496\n",
      "F1 score at threshold 0.11 is 0.6522185175686074\n",
      "F1 score at threshold 0.12 is 0.6615223646351034\n",
      "F1 score at threshold 0.13 is 0.6708366604560376\n",
      "F1 score at threshold 0.14 is 0.6779110670154235\n",
      "F1 score at threshold 0.15 is 0.6857770858137192\n",
      "F1 score at threshold 0.16 is 0.6939895794566432\n",
      "F1 score at threshold 0.17 is 0.6997549019607843\n",
      "F1 score at threshold 0.18 is 0.705119030580602\n",
      "F1 score at threshold 0.19 is 0.711104670820654\n",
      "F1 score at threshold 0.2 is 0.715961294106148\n",
      "F1 score at threshold 0.21 is 0.7203042426038424\n",
      "F1 score at threshold 0.22 is 0.7238009771662179\n",
      "F1 score at threshold 0.23 is 0.727437641723356\n",
      "F1 score at threshold 0.24 is 0.7311335166513901\n",
      "F1 score at threshold 0.25 is 0.7345869297163994\n",
      "F1 score at threshold 0.26 is 0.7372183372183372\n",
      "F1 score at threshold 0.27 is 0.7401599498196644\n",
      "F1 score at threshold 0.28 is 0.7435383479269965\n",
      "F1 score at threshold 0.29 is 0.7456761215475494\n",
      "F1 score at threshold 0.3 is 0.7463022508038585\n",
      "F1 score at threshold 0.31 is 0.7477462887989205\n",
      "F1 score at threshold 0.32 is 0.7496193169458343\n",
      "F1 score at threshold 0.33 is 0.7510271158586689\n",
      "F1 score at threshold 0.34 is 0.7514623110032005\n",
      "F1 score at threshold 0.35 is 0.7529594842438726\n",
      "F1 score at threshold 0.36 is 0.7539900319202554\n",
      "F1 score at threshold 0.37 is 0.7559543966587652\n",
      "F1 score at threshold 0.38 is 0.7561724883376947\n",
      "F1 score at threshold 0.39 is 0.7561339142398532\n",
      "F1 score at threshold 0.4 is 0.7561890472618154\n",
      "F1 score at threshold 0.41 is 0.7572308049715414\n",
      "F1 score at threshold 0.42 is 0.758305501845667\n",
      "F1 score at threshold 0.43 is 0.7574201923644303\n",
      "F1 score at threshold 0.44 is 0.7570520814775225\n",
      "F1 score at threshold 0.45 is 0.756071300394784\n",
      "F1 score at threshold 0.46 is 0.755750933397567\n",
      "F1 score at threshold 0.47 is 0.7547925260859015\n",
      "F1 score at threshold 0.48 is 0.7541704857928505\n",
      "F1 score at threshold 0.49 is 0.7533427814406309\n",
      "F1 score at threshold 0.5 is 0.7509788080293333\n",
      "Best threshold:  0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "pred_val_y = model_treated.predict([X_t_chk], batch_size=1024, verbose=1)\n",
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = f1_score(y_chk_treated, (pred_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh_1 = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh_1)\n",
    "\n",
    "#y_pred = model_treated.predict(X_test_treated, batch_size=1024, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/quora-insincere-questions-classification/sample_submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_hat > best_thresh_1).astype(int)\n",
    "submission['prediction'] = y_pred\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
